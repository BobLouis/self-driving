{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import *\n",
    "from IPython.display import HTML\n",
    "import os\n",
    "def calibrate_camera():\n",
    "\t# 棋盘格个数及其横纵内角点个数\n",
    "\tobjp_dict = {\n",
    "\t\t1: (9, 6),\n",
    "\t\t2: (9, 6),\n",
    "\t\t3: (9, 6),\n",
    "\t\t4: (9, 6),\n",
    "\t\t5: (9, 6),\n",
    "\t\t6: (9, 6),\n",
    "\t\t7: (9, 6),\n",
    "\t\t8: (9, 6),\n",
    "\t\t9: (9, 6),\n",
    "\t\t10: (9, 6),\n",
    "\t\t11: (9, 6),\n",
    "\t\t12: (9, 6),\n",
    "\t\t13: (9, 6),\n",
    "\t\t14: (9, 6),\n",
    "\t\t15: (9, 6),\n",
    "\t\t16: (9, 6),\n",
    "\t\t17: (9, 6),\n",
    "\t\t18: (9, 6),\n",
    "\t\t19: (9, 6),\n",
    "\t\t20: (9, 6),\n",
    "\t}\n",
    "\n",
    "\tobjp_list = []\n",
    "\tcorners_list = []\n",
    "\n",
    "\tfor k in objp_dict:\n",
    "\t\tnx, ny = objp_dict[k]\n",
    "\t\tobjp = np.zeros((nx*ny,3), np.float32)\n",
    "\t\tobjp[:,:2] = np.mgrid[0:nx, 0:ny].T.reshape(-1,2)\n",
    "\t\tfname = 'camera_cal/calibration%s.jpg' % str(k)\n",
    "\t\timg = cv2.imread(fname)\n",
    "\t\tgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\t\t# 棋盘格角点\n",
    "\t\tret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "\n",
    "\t\tif ret == True:\n",
    "\t\t\tobjp_list.append(objp)\n",
    "\t\t\tcorners_list.append(corners)\n",
    "\t\telse:\n",
    "\t\t\tprint('Warning: ret = %s for %s' % (ret, fname))\n",
    "\n",
    "\t# 相机标定\n",
    "\timg = cv2.imread('test_images/straight_lines1.jpg')\n",
    "\timg_size = (img.shape[1], img.shape[0])\n",
    "\tret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objp_list, corners_list, img_size,None,None)\n",
    "\n",
    "\treturn mtx, dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_of_interest(img, vertices):\n",
    "    mask = np.zeros_like(img)\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "\n",
    "    return masked_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_sobel_thresh(img, orient='x', thresh_min=20, thresh_max=100):\n",
    "\tgray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\tif orient == 'x':\n",
    "\t\tabs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0))\n",
    "\tif orient == 'y':\n",
    "\t\tabs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1))\n",
    "\n",
    "\tscaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "\tbinary_output = np.zeros_like(scaled_sobel)\n",
    "\tbinary_output[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "\n",
    "\treturn binary_output\n",
    "\n",
    "# SobelXY梯度信息\n",
    "def mag_thresh(img, sobel_kernel=3, mag_thresh=(30, 100)):\n",
    "\tgray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\tsobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "\tsobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "\tgradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "\tscale_factor = np.max(gradmag)/255\n",
    "\tgradmag = (gradmag/scale_factor).astype(np.uint8)\n",
    "\tbinary_output = np.zeros_like(gradmag)\n",
    "\tbinary_output[(gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1])] = 1\n",
    "\n",
    "\treturn binary_output\n",
    "\n",
    "# direction信息\n",
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "\tgray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\tsobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "\tsobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "\tabsgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "\tbinary_output =  np.zeros_like(absgraddir)\n",
    "\tbinary_output[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 1\n",
    "\n",
    "\treturn binary_output\n",
    "\n",
    "# S通道信息\n",
    "def hls_thresh(img, thresh=(100, 255)):\n",
    "\thls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "\ts_channel = hls[:,:,2]\n",
    "\tbinary_output = np.zeros_like(s_channel)\n",
    "\tbinary_output[(s_channel > thresh[0]) & (s_channel <= thresh[1])] = 1\n",
    "\n",
    "\treturn binary_output\n",
    "\n",
    "# 叠加信息，四组阈值可以适当调整\n",
    "def combined_thresh(img):\n",
    "\tabs_bin = abs_sobel_thresh(img, orient='x', thresh_min=35, thresh_max=100)\n",
    "\tmag_bin = mag_thresh(img, sobel_kernel=3, mag_thresh=(30, 255))\n",
    "\tdir_bin = dir_threshold(img, sobel_kernel=15, thresh=(0.7, 1.3))\n",
    "\thls_bin = hls_thresh(img, thresh=(80, 255))\n",
    "\n",
    "\tcombined = np.zeros_like(dir_bin)\n",
    "\tcombined[(abs_bin == 1 | ((mag_bin == 1) & (dir_bin == 1))) | hls_bin == 1] = 1\n",
    "\n",
    "\treturn combined, abs_bin, mag_bin, dir_bin, hls_bin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perspective_transform(img):\n",
    "\timg_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "    # 源点（左下，左上，右上，右下）\n",
    "\tsrc = np.float32([[310, 1080],[750, 760],[910, 760],[1370, 1080]])\n",
    "\t# 目标点（左下，左上，右上，右下）\n",
    "\tdst = np.float32([[500,1080],[500,0],[1300,0], [1300,1080]])\n",
    "\n",
    "\t# 透射变换矩阵，逆透视变换矩阵\n",
    "\tm = cv2.getPerspectiveTransform(src, dst)\n",
    "\tm_inv = cv2.getPerspectiveTransform(dst, src)\n",
    "\n",
    "\twarped = cv2.warpPerspective(img, m, img_size, flags=cv2.INTER_LINEAR)\n",
    "\tunwarped = cv2.warpPerspective(warped, m_inv, (warped.shape[1], warped.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "\treturn warped, unwarped, m, m_inv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_fit(binary_warped):\n",
    "\t# 直方图\n",
    "\thistogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "\tout_img = (np.dstack((binary_warped, binary_warped, binary_warped))*255).astype('uint8')\n",
    "\tmidpoint = np.int(histogram.shape[0]/2)\n",
    "\tleftx_base = np.argmax(histogram[100:midpoint]) + 100\n",
    "\trightx_base = np.argmax(histogram[midpoint:-100]) + midpoint\n",
    "\n",
    "\t# 滑窗数目\n",
    "\tnwindows = 9\n",
    "\twindow_height = np.int(binary_warped.shape[0]/nwindows)\n",
    "\tnonzero = binary_warped.nonzero()\n",
    "\tnonzeroy = np.array(nonzero[0])\n",
    "\tnonzerox = np.array(nonzero[1])\n",
    "\tleftx_current = leftx_base\n",
    "\trightx_current = rightx_base\n",
    "\t# 滑窗宽度允许变动阈值\n",
    "\tmargin = 100\n",
    "\t# 滑窗面积阈值\n",
    "\tminpix = 50\n",
    "\n",
    "\tleft_lane_inds = []\n",
    "\tright_lane_inds = []\n",
    "\n",
    "\tfor window in range(nwindows):\n",
    "\t\twin_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "\t\twin_y_high = binary_warped.shape[0] - window*window_height\n",
    "\n",
    "\t\twin_xleft_low = leftx_current - margin\n",
    "\t\twin_xleft_high = leftx_current + margin\n",
    "\t\twin_xright_low = rightx_current - margin\n",
    "\t\twin_xright_high = rightx_current + margin\n",
    "\n",
    "\t\tcv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2)\n",
    "\t\tcv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2)\n",
    "\n",
    "\t\tgood_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "\t\tgood_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "\n",
    "\t\tleft_lane_inds.append(good_left_inds)\n",
    "\t\tright_lane_inds.append(good_right_inds)\n",
    "\n",
    "\t\tif len(good_left_inds) > minpix:\n",
    "\t\t\tleftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "\t\tif len(good_right_inds) > minpix:\n",
    "\t\t\trightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "\tleft_lane_inds = np.concatenate(left_lane_inds)\n",
    "\tright_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "\tleftx = nonzerox[left_lane_inds]\n",
    "\tlefty = nonzeroy[left_lane_inds]\n",
    "\trightx = nonzerox[right_lane_inds]\n",
    "\trighty = nonzeroy[right_lane_inds]\n",
    "\n",
    "\tleft_fit = np.polyfit(lefty, leftx, 2)\n",
    "\tright_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "\tret = {}\n",
    "\tret['left_fit'] = left_fit\n",
    "\tret['right_fit'] = right_fit\n",
    "\tret['nonzerox'] = nonzerox\n",
    "\tret['nonzeroy'] = nonzeroy\n",
    "\tret['out_img'] = out_img\n",
    "\tret['left_lane_inds'] = left_lane_inds\n",
    "\tret['right_lane_inds'] = right_lane_inds\n",
    "\n",
    "\treturn ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算曲率半径\n",
    "def calc_curve(left_lane_inds, right_lane_inds, nonzerox, nonzeroy):\n",
    "\t# 图片高度最大值索引\n",
    "\ty_eval = 1079\n",
    "\n",
    "\t# 图片单位像素与米的换算关系\n",
    "\txm_per_pix = 3.75 / 1100\n",
    "\tym_per_pix = 30 / 720\n",
    "\n",
    "\tleftx = nonzerox[left_lane_inds]\n",
    "\tlefty = nonzeroy[left_lane_inds]\n",
    "\trightx = nonzerox[right_lane_inds]\n",
    "\trighty = nonzeroy[right_lane_inds]\n",
    "\n",
    "\tleft_fit_cr = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "\tright_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "\n",
    "\tleft_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "\tright_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "\n",
    "\treturn left_curverad, right_curverad\n",
    "\n",
    "# 计算距车道中心偏移量\n",
    "def calc_vehicle_offset(undist, left_fit, right_fit):\n",
    "\tbottom_y = undist.shape[0] - 1\n",
    "\tbottom_x_left = left_fit[0]*(bottom_y**2) + left_fit[1]*bottom_y + left_fit[2]\n",
    "\tbottom_x_right = right_fit[0]*(bottom_y**2) + right_fit[1]*bottom_y + right_fit[2]\n",
    "\tvehicle_offset = undist.shape[1]/2 - (bottom_x_left + bottom_x_right)/2\n",
    "\t# 图片单位像素与米的换算关系\n",
    "\txm_per_pix = 3.75/1100\n",
    "\tvehicle_offset *= xm_per_pix\n",
    "\n",
    "\treturn vehicle_offset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_viz(undist, left_fit, right_fit, m_inv, left_curve, right_curve, vehicle_offset):\n",
    "\tploty = np.linspace(0, undist.shape[0]-1, undist.shape[0])\n",
    "\tleft_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "\tright_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "\t# 创建图片\n",
    "\tcolor_warp = np.zeros((1080, 1920, 3), dtype='uint8')\n",
    "\n",
    "\tpts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "\tpts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "\tpts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "\tcv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "\tnewwarp = cv2.warpPerspective(color_warp, m_inv, (undist.shape[1], undist.shape[0]))\n",
    "\tresult = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "\n",
    "\t# 图片右上角显示曲率半径，中心偏移量\n",
    "\tavg_curve = (left_curve + right_curve)/2\n",
    "\tstring1 = 'R_mean : %.1f m' % avg_curve\n",
    "\tif left_fit[0] > 0 and avg_curve > 500:\n",
    "\t\tstring2 = \"gentle right\"\n",
    "\telif left_fit[0] > 0 and avg_curve <= 500:\n",
    "\t\tstring2 = \"hard right\"\n",
    "\telif left_fit[0] < 0 and avg_curve > 500:\n",
    "\t\tstring2 = \"gentle left\"\n",
    "\telif left_fit[0] < 0 and avg_curve <= 500:\n",
    "\t\tstring2 = \"hard left\"\n",
    "\tstring3 = 'central offset: %.1f m' % vehicle_offset\n",
    "\n",
    "\tfont = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\tcv2.putText(result, string1, (1500, 100), font, 0.9, (0, 0, 0), 4, cv2.LINE_AA)\n",
    "\tcv2.putText(result, string2, (1500, 300), font, 0.9, (0, 0, 0), 4, cv2.LINE_AA)\n",
    "\tcv2.putText(result, string3, (1500, 200), font, 0.9, (0, 0, 0), 4, cv2.LINE_AA)\n",
    "\n",
    "\t# 图片上方显示消除失真图，鸟瞰图，车道线检测图\n",
    "\tsmall_undist = cv2.resize(undist, (0, 0), fx=0.2, fy=0.2)\n",
    "\tbird_eye, _, _, _ = perspective_transform(undist)\n",
    "\tsmall_bird_eye = cv2.resize(bird_eye, (0, 0), fx=0.2, fy=0.2)\n",
    "\n",
    "\timg = cv2.cvtColor(undist, cv2.COLOR_BGR2RGB)\n",
    "\tvertices = np.int32([[(50, 1080), (700, 760), (920, 760), (1400, 1080)]])\n",
    "\tmasked_image = region_of_interest(img, vertices)\n",
    "\tcv2.line(masked_image, (50, 1080), (700, 760), (0, 0, 0), 10)\n",
    "\tcv2.line(masked_image, (920, 760), (1400, 1080), (0, 0, 0), 25)\n",
    "\timg, abs_bin, mag_bin, dir_bin, hls_bin = combined_thresh(masked_image)\n",
    "\tbinary_warped, binary_unwarped, m, m_inv = perspective_transform(img)\n",
    "\tret = line_fit(binary_warped)\n",
    "\tout_image = viz2(binary_warped, ret)\n",
    "\tsmall_out_image = cv2.resize(out_image, (0, 0), fx=0.2, fy=0.2)\n",
    "\n",
    "\tx1 = 0\n",
    "\ty1 = 100\n",
    "\tx2 = small_out_image.shape[0]\n",
    "\ty2 = small_out_image.shape[1]\n",
    "\ty3 = small_out_image.shape[1] * 2\n",
    "\ty4 = small_out_image.shape[1] * 3\n",
    "\tresult[x1 + 100:x2 + 100, y1:y2 + 100, :] = small_undist\n",
    "\tresult[x1 + 100:x2 + 100, y2 + 200:y3 + 200, :] = small_bird_eye\n",
    "\tresult[x1 + 100:x2 + 100, y3 + 300:y4 + 300, :] = small_out_image\n",
    "\tcv2.putText(result, \"Undist\", (100, 80), font, 0.9, (0, 0, 0), 4, cv2.LINE_AA)\n",
    "\tcv2.putText(result, \"Bird's Eye\", (580, 80), font, 0.9, (0, 0, 0), 4, cv2.LINE_AA)\n",
    "\tcv2.putText(result, \"Line Search\", (1080, 80), font, 0.9, (0, 0, 0), 4, cv2.LINE_AA)\n",
    "\n",
    "\treturn result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
